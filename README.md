# Final Year Project: Goal Conditioned Reinforcement Learning -- Nanyang Technological University  
Latest updates from my Final Year Project dedicated at **Solving Sparse Reward Problem with Goal Conditioned Reinforcement Learning.** that I have completed during my Bachelors Degree at time at Nanyang Technological University. This is a year long-project done under the supervision of Professor Arvind Easwaran and Dr. Arambam James Singh. The following was the research objective given:

> Goal-conditioned reinforcement learning(GCRL) is a sub-field of RL where the objective is to train an agent to achieve multiple goals in an environment. The problem setting in GCRL is slightly different from a traditional RL setting where the agent only learns to maximize a long-term reward, such setting is considered to be a single goal setting. However, in GCRL with multiple goals, our aim is to develop an agent which can learn a more generalized behavior(or diverse skills) for the distribution of goals.

After a year of work, the conclusion of the project yielded positive results in the production of a novel algorithm for sub-goal generation to increase training efficiency in reward sparse environments. This new algorithm is not included in this doc for confidentially matters. However, it will be included now. This document contains a background about Goal Conditioned Reinforcement Learning and the problem of Sparse Rewards. Note that if you are a beginner to Reinforcement Learning, it will benefit you to know about basics of Reinforcement Learning before. There are countless learning resources available. Many of them are free too. I have also written a blog on Reinforcement Learning on my website that you can check out too. The following section describes the Sparse Reward Problem and the Goal Conditioned Reinforcement Learning.  


Standard Reinforcement Learning is adept at playing games, solving mazes, etc. However, as the environments get increasingly complexed, these algorithms become too inefficient. Now what does a complex environment mean? There are many definitions of complex environments. For example, a complex environment can be characterized by the large state space. There are too many positions for the agent to be in, requiring each state to have a positive meaning. Another way to classify complex environments is through stochasticity. This is when the output of an agent's actions produces unexpected results. However, in this article, when I refer to complex environment, I will not be refering to these characteritistcs. In this article, a complex environment will be defined only by the reward sparsity(the ratio of states in an environment that yield a reward to the agent to states that yield no reward). In a typical sparse reward environment, there is only 1 state that provides a reward and this goal is too far away. Let's consider the following environment. In this environment, the agent has to arrive at the goal. If you already have experience with RL, you will understand how difficult it's for standard RL to arrive at this goal. During the training phase, the agent is expected to make random moves
